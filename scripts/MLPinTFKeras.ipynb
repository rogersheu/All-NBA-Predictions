{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46ff009f",
   "metadata": {},
   "source": [
    "##### All-Star/NBA Predictions\n",
    "\n",
    "MLP implementation with Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a8a9ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c7b0a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All players data loaded.\n"
     ]
    }
   ],
   "source": [
    "fileName = 'C:/Users/Roger/Documents/GitHub/All-Star-Predictions/baseData/ML/all_stats_20211201.csv'\n",
    "df = pd.read_csv(fileName)\n",
    "print('All players data loaded.')\n",
    "\n",
    "X = df[['RPG','APG','SBPG','PPG','TS','WS48','Perc']]\n",
    "y = df['allLeague']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "eec6ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "fdd3d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "#X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "#X_test = tf.keras.utils.normalize(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "4a8a80aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(Dense(4, activation='relu', name = \"hidden1\"))\n",
    "\n",
    "#model.add(Dense(2, activation='relu', name = \"hidden1\"))\n",
    "#model.add(Dense(2, activation='relu', name = \"hidden2\"))\n",
    "model.add(Dense(1, activation='sigmoid', name = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "60060c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=\"binary_crossentropy\",\n",
    "             metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "3edf7482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.6551 - accuracy: 0.6552\n",
      "Epoch 2/100\n",
      "186/186 [==============================] - 0s 444us/step - loss: 0.4183 - accuracy: 0.8432\n",
      "Epoch 3/100\n",
      "186/186 [==============================] - 0s 444us/step - loss: 0.3182 - accuracy: 0.8956\n",
      "Epoch 4/100\n",
      "186/186 [==============================] - 0s 482us/step - loss: 0.2623 - accuracy: 0.9184\n",
      "Epoch 5/100\n",
      "186/186 [==============================] - 0s 482us/step - loss: 0.2214 - accuracy: 0.9336\n",
      "Epoch 6/100\n",
      "186/186 [==============================] - 0s 471us/step - loss: 0.2015 - accuracy: 0.9262\n",
      "Epoch 7/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.1840 - accuracy: 0.9270\n",
      "Epoch 8/100\n",
      "186/186 [==============================] - 0s 482us/step - loss: 0.1707 - accuracy: 0.9337\n",
      "Epoch 9/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1575 - accuracy: 0.9387\n",
      "Epoch 10/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.1680 - accuracy: 0.9298\n",
      "Epoch 11/100\n",
      "186/186 [==============================] - 0s 471us/step - loss: 0.1541 - accuracy: 0.9359\n",
      "Epoch 12/100\n",
      "186/186 [==============================] - 0s 442us/step - loss: 0.1532 - accuracy: 0.9376\n",
      "Epoch 13/100\n",
      "186/186 [==============================] - 0s 465us/step - loss: 0.1603 - accuracy: 0.9293\n",
      "Epoch 14/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1585 - accuracy: 0.9357\n",
      "Epoch 15/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1533 - accuracy: 0.9316\n",
      "Epoch 16/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.1497 - accuracy: 0.9352\n",
      "Epoch 17/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1599 - accuracy: 0.9316\n",
      "Epoch 18/100\n",
      "186/186 [==============================] - 0s 465us/step - loss: 0.1511 - accuracy: 0.9393\n",
      "Epoch 19/100\n",
      "186/186 [==============================] - 0s 444us/step - loss: 0.1492 - accuracy: 0.9396\n",
      "Epoch 20/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1534 - accuracy: 0.9376\n",
      "Epoch 21/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1395 - accuracy: 0.9414\n",
      "Epoch 22/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.1455 - accuracy: 0.9425\n",
      "Epoch 23/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.1507 - accuracy: 0.9371\n",
      "Epoch 24/100\n",
      "186/186 [==============================] - 0s 453us/step - loss: 0.1425 - accuracy: 0.9406\n",
      "Epoch 25/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1464 - accuracy: 0.9400\n",
      "Epoch 26/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1432 - accuracy: 0.9414\n",
      "Epoch 27/100\n",
      "186/186 [==============================] - 0s 444us/step - loss: 0.1413 - accuracy: 0.9408\n",
      "Epoch 28/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.1530 - accuracy: 0.9307\n",
      "Epoch 29/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1446 - accuracy: 0.9367\n",
      "Epoch 30/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1498 - accuracy: 0.9407\n",
      "Epoch 31/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1380 - accuracy: 0.9410\n",
      "Epoch 32/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1448 - accuracy: 0.9390\n",
      "Epoch 33/100\n",
      "186/186 [==============================] - 0s 452us/step - loss: 0.1618 - accuracy: 0.9308\n",
      "Epoch 34/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1470 - accuracy: 0.9390\n",
      "Epoch 35/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.1503 - accuracy: 0.9348\n",
      "Epoch 36/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1479 - accuracy: 0.9371\n",
      "Epoch 37/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1304 - accuracy: 0.9475\n",
      "Epoch 38/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1381 - accuracy: 0.9387\n",
      "Epoch 39/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1409 - accuracy: 0.9423\n",
      "Epoch 40/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.1435 - accuracy: 0.9400\n",
      "Epoch 41/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1388 - accuracy: 0.9411\n",
      "Epoch 42/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1461 - accuracy: 0.9361\n",
      "Epoch 43/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1344 - accuracy: 0.9414\n",
      "Epoch 44/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1386 - accuracy: 0.9401\n",
      "Epoch 45/100\n",
      "186/186 [==============================] - 0s 444us/step - loss: 0.1500 - accuracy: 0.9402\n",
      "Epoch 46/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1421 - accuracy: 0.9400\n",
      "Epoch 47/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.1407 - accuracy: 0.9442\n",
      "Epoch 48/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1416 - accuracy: 0.9438\n",
      "Epoch 49/100\n",
      "186/186 [==============================] - 0s 444us/step - loss: 0.1509 - accuracy: 0.9413\n",
      "Epoch 50/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1376 - accuracy: 0.9425\n",
      "Epoch 51/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1427 - accuracy: 0.9390\n",
      "Epoch 52/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1466 - accuracy: 0.9373\n",
      "Epoch 53/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1418 - accuracy: 0.9420\n",
      "Epoch 54/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1408 - accuracy: 0.9408\n",
      "Epoch 55/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1457 - accuracy: 0.9341\n",
      "Epoch 56/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1423 - accuracy: 0.9412\n",
      "Epoch 57/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.1410 - accuracy: 0.9402\n",
      "Epoch 58/100\n",
      "186/186 [==============================] - 0s 465us/step - loss: 0.1511 - accuracy: 0.9407\n",
      "Epoch 59/100\n",
      "186/186 [==============================] - 0s 444us/step - loss: 0.1400 - accuracy: 0.9422\n",
      "Epoch 60/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1394 - accuracy: 0.9416\n",
      "Epoch 61/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1321 - accuracy: 0.9433\n",
      "Epoch 62/100\n",
      "186/186 [==============================] - 0s 444us/step - loss: 0.1452 - accuracy: 0.9392\n",
      "Epoch 63/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1402 - accuracy: 0.9404\n",
      "Epoch 64/100\n",
      "186/186 [==============================] - 0s 438us/step - loss: 0.1380 - accuracy: 0.9427\n",
      "Epoch 65/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1410 - accuracy: 0.9414\n",
      "Epoch 66/100\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.1457 - accuracy: 0.9395\n",
      "Epoch 67/100\n",
      "186/186 [==============================] - 0s 557us/step - loss: 0.1402 - accuracy: 0.9437\n",
      "Epoch 68/100\n",
      "186/186 [==============================] - 0s 584us/step - loss: 0.1390 - accuracy: 0.9409\n",
      "Epoch 69/100\n",
      "186/186 [==============================] - 0s 498us/step - loss: 0.1348 - accuracy: 0.9415\n",
      "Epoch 70/100\n",
      "186/186 [==============================] - 0s 487us/step - loss: 0.1337 - accuracy: 0.9443\n",
      "Epoch 71/100\n",
      "186/186 [==============================] - 0s 508us/step - loss: 0.1444 - accuracy: 0.9435\n",
      "Epoch 72/100\n",
      "186/186 [==============================] - 0s 573us/step - loss: 0.1488 - accuracy: 0.9388\n",
      "Epoch 73/100\n",
      "186/186 [==============================] - 0s 757us/step - loss: 0.1429 - accuracy: 0.9408\n",
      "Epoch 74/100\n",
      "186/186 [==============================] - 0s 611us/step - loss: 0.1484 - accuracy: 0.9369\n",
      "Epoch 75/100\n",
      "186/186 [==============================] - 0s 611us/step - loss: 0.1350 - accuracy: 0.9446\n",
      "Epoch 76/100\n",
      "186/186 [==============================] - 0s 536us/step - loss: 0.1380 - accuracy: 0.9427\n",
      "Epoch 77/100\n",
      "186/186 [==============================] - 0s 736us/step - loss: 0.1463 - accuracy: 0.9371\n",
      "Epoch 78/100\n",
      "186/186 [==============================] - 0s 557us/step - loss: 0.1460 - accuracy: 0.9375\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 0s 512us/step - loss: 0.1334 - accuracy: 0.9443\n",
      "Epoch 80/100\n",
      "186/186 [==============================] - 0s 465us/step - loss: 0.1483 - accuracy: 0.9378\n",
      "Epoch 81/100\n",
      "186/186 [==============================] - 0s 465us/step - loss: 0.1509 - accuracy: 0.9350\n",
      "Epoch 82/100\n",
      "186/186 [==============================] - 0s 703us/step - loss: 0.1412 - accuracy: 0.9424\n",
      "Epoch 83/100\n",
      "186/186 [==============================] - 0s 633us/step - loss: 0.1412 - accuracy: 0.9422\n",
      "Epoch 84/100\n",
      "186/186 [==============================] - 0s 617us/step - loss: 0.1468 - accuracy: 0.9352\n",
      "Epoch 85/100\n",
      "186/186 [==============================] - 0s 476us/step - loss: 0.1365 - accuracy: 0.9431\n",
      "Epoch 86/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.1432 - accuracy: 0.9421\n",
      "Epoch 87/100\n",
      "186/186 [==============================] - 0s 465us/step - loss: 0.1521 - accuracy: 0.9352\n",
      "Epoch 88/100\n",
      "186/186 [==============================] - 0s 471us/step - loss: 0.1465 - accuracy: 0.9384\n",
      "Epoch 89/100\n",
      "186/186 [==============================] - 0s 465us/step - loss: 0.1441 - accuracy: 0.9379\n",
      "Epoch 90/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1536 - accuracy: 0.9359\n",
      "Epoch 91/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1416 - accuracy: 0.9438\n",
      "Epoch 92/100\n",
      "186/186 [==============================] - 0s 476us/step - loss: 0.1463 - accuracy: 0.9426\n",
      "Epoch 93/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.1430 - accuracy: 0.9429\n",
      "Epoch 94/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1416 - accuracy: 0.9419\n",
      "Epoch 95/100\n",
      "186/186 [==============================] - 0s 471us/step - loss: 0.1396 - accuracy: 0.9426\n",
      "Epoch 96/100\n",
      "186/186 [==============================] - 0s 471us/step - loss: 0.1502 - accuracy: 0.9367\n",
      "Epoch 97/100\n",
      "186/186 [==============================] - 0s 465us/step - loss: 0.1438 - accuracy: 0.9405\n",
      "Epoch 98/100\n",
      "186/186 [==============================] - 0s 454us/step - loss: 0.1486 - accuracy: 0.9354\n",
      "Epoch 99/100\n",
      "186/186 [==============================] - 0s 476us/step - loss: 0.1403 - accuracy: 0.9396\n",
      "Epoch 100/100\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.1519 - accuracy: 0.9418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2892dc7dc40>"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "9ed3b58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 457us/step - loss: 0.1431 - accuracy: 0.9434\n",
      "0.14305517077445984 0.9434343576431274\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "a6fffc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, model.predict(X_test)\n",
    "\n",
    "y_pred_bin = np.zeros([len(y_pred),1], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "a6e71df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1252   25]\n",
      " [  59  149]]\n"
     ]
    }
   ],
   "source": [
    "for index, item in enumerate(y_pred):\n",
    "    #print(item)\n",
    "    if item > 0.5:\n",
    "        y_pred_bin[index] = [1]\n",
    "    else:\n",
    "        y_pred_bin[index] = [0]\n",
    "        \n",
    "print(confusion_matrix(y_true, y_pred_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "6af69cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      1277\n",
      "           1       0.86      0.72      0.78       208\n",
      "\n",
      "    accuracy                           0.94      1485\n",
      "   macro avg       0.91      0.85      0.87      1485\n",
      "weighted avg       0.94      0.94      0.94      1485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "57fbdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = pd.read_csv(\"C:/Users/Roger/Documents/GitHub/All-Star-Predictions/baseData/dailystats/2022-01-06/stats_20220106.csv\")\n",
    "X_2022 = df_2022[['RPG','APG','SBPG','PPG','TS','WS48','Perc']]\n",
    "#X_2022 = tf.keras.utils.normalize(X_2022, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "85da020c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Year</th>\n",
       "      <th>G</th>\n",
       "      <th>MP</th>\n",
       "      <th>MPG</th>\n",
       "      <th>RPG</th>\n",
       "      <th>APG</th>\n",
       "      <th>SBPG</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TS</th>\n",
       "      <th>rTS</th>\n",
       "      <th>WS48</th>\n",
       "      <th>Perc</th>\n",
       "      <th>Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precious Achiuwa</td>\n",
       "      <td>2022</td>\n",
       "      <td>26</td>\n",
       "      <td>641</td>\n",
       "      <td>25.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.003386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>2022</td>\n",
       "      <td>39</td>\n",
       "      <td>1004</td>\n",
       "      <td>26.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.006288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nickeil Alexander-Walker</td>\n",
       "      <td>2022</td>\n",
       "      <td>35</td>\n",
       "      <td>968</td>\n",
       "      <td>28.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.464</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.005368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grayson Allen</td>\n",
       "      <td>2022</td>\n",
       "      <td>36</td>\n",
       "      <td>1023</td>\n",
       "      <td>28.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.002272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jarrett Allen</td>\n",
       "      <td>2022</td>\n",
       "      <td>31</td>\n",
       "      <td>1016</td>\n",
       "      <td>33.4</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.163855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Kenrich Williams</td>\n",
       "      <td>2022</td>\n",
       "      <td>34</td>\n",
       "      <td>708</td>\n",
       "      <td>21.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.534</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.000594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Robert Williams</td>\n",
       "      <td>2022</td>\n",
       "      <td>29</td>\n",
       "      <td>829</td>\n",
       "      <td>29.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.007248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Christian Wood</td>\n",
       "      <td>2022</td>\n",
       "      <td>36</td>\n",
       "      <td>1112</td>\n",
       "      <td>31.5</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.556</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.102544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Trae Young</td>\n",
       "      <td>2022</td>\n",
       "      <td>33</td>\n",
       "      <td>1143</td>\n",
       "      <td>35.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.621039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>2022</td>\n",
       "      <td>35</td>\n",
       "      <td>876</td>\n",
       "      <td>25.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.003408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Player  Year   G    MP   MPG   RPG  APG  SBPG   PPG  \\\n",
       "0            Precious Achiuwa  2022  26   641  25.1   7.8  1.6   1.1   8.1   \n",
       "1                Steven Adams  2022  39  1004  26.2   9.4  3.0   1.4   7.2   \n",
       "2    Nickeil Alexander-Walker  2022  35   968  28.2   3.8  2.6   1.3  13.8   \n",
       "3               Grayson Allen  2022  36  1023  28.9   3.4  1.4   1.2  12.1   \n",
       "4               Jarrett Allen  2022  31  1016  33.4  10.9  1.9   2.4  17.4   \n",
       "..                        ...   ...  ..   ...   ...   ...  ...   ...   ...   \n",
       "190          Kenrich Williams  2022  34   708  21.2   4.0  1.9   1.1   7.2   \n",
       "191           Robert Williams  2022  29   829  29.1   9.1  1.8   2.7  10.0   \n",
       "192            Christian Wood  2022  36  1112  31.5  10.6  2.2   1.6  17.3   \n",
       "193                Trae Young  2022  33  1143  35.3   4.0  9.7   1.0  28.9   \n",
       "194               Ivica Zubac  2022  35   876  25.5   8.4  1.1   1.7   9.8   \n",
       "\n",
       "        TS    rTS   WS48   Perc      Prob  \n",
       "0    0.439 -0.118  0.039  0.514  0.003386  \n",
       "1    0.568  0.011  0.148  0.641  0.006288  \n",
       "2    0.464 -0.093 -0.013  0.342  0.005368  \n",
       "3    0.572  0.015  0.107  0.625  0.002272  \n",
       "4    0.720  0.163  0.258  0.553  0.163855  \n",
       "..     ...    ...    ...    ...       ...  \n",
       "190  0.534 -0.023  0.096  0.351  0.000594  \n",
       "191  0.737  0.180  0.224  0.474  0.007248  \n",
       "192  0.556 -0.001  0.091  0.282  0.102544  \n",
       "193  0.588  0.031  0.179  0.459  0.621039  \n",
       "194  0.694  0.137  0.203  0.500  0.003408  \n",
       "\n",
       "[195 rows x 14 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2022pred = df_2022.copy()\n",
    "X_predicted = model.predict(X_2022)\n",
    "df_2022pred['Prob'] = [i[0] for i in X_predicted]\n",
    "df_2022pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ce587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
